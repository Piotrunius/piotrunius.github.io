name: Update and Deploy

on:
  push:
    branches: ["main"]
    paths-ignore:
      - 'data/**' # Nie uruchamiaj przy zmianach w danych (zapobiega pętli)
  schedule:
    - cron: '*/15 * * * *'
  workflow_dispatch:

permissions:
  contents: write
  pages: write
  id-token: write

concurrency:
  group: pages-flow
  cancel-in-progress: false

jobs:
  update-and-deploy:
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Fetch Stats
        id: fetch
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          STEAM_API_KEY: ${{ secrets.STEAM_API_KEY }}
          STEAM_ID64: ${{ secrets.STEAM_ID64 }}
        run: |
          cat << 'EOF' > update.js
          const fs = require('fs');
          const https = require('https');
          const isGithubTime = true;
          
          // Utility: Retry logic with exponential backoff
          async function fetchWithRetry(url, options = {}, retries = 3, delay = 1000) {
            for (let i = 0; i < retries; i++) {
              try {
                const response = await fetch(url, options);
                if (!response.ok) {
                  const rateLimitRemaining = response.headers.get('x-ratelimit-remaining');
                  const rateLimitReset = response.headers.get('x-ratelimit-reset');
                  
                  if (response.status === 403 && rateLimitRemaining === '0') {
                    const resetTime = new Date(rateLimitReset * 1000);
                    console.warn(`Rate limit exceeded. Resets at ${resetTime}`);
                    if (i < retries - 1) {
                      await new Promise(resolve => setTimeout(resolve, delay * Math.pow(2, i)));
                      continue;
                    }
                  }
                  throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                }
                return response;
              } catch (error) {
                console.error(`Attempt ${i + 1} failed:`, error.message);
                if (i < retries - 1) {
                  await new Promise(resolve => setTimeout(resolve, delay * Math.pow(2, i)));
                } else {
                  throw error;
                }
              }
            }
          }
          
          // Utility: Validate and sanitize data
          function sanitizeString(str, maxLength = 500) {
            if (typeof str !== 'string') return '';
            return str.slice(0, maxLength).trim();
          }
          
          async function run() {
            if (!fs.existsSync('./data')) fs.mkdirSync('./data');
            
            // Load previous data as fallback
            let previousSteamData = {};
            let previousGithubData = {};
            
            try {
              if (fs.existsSync('./data/steam-status.json')) {
                previousSteamData = JSON.parse(fs.readFileSync('./data/steam-status.json', 'utf8'));
              }
            } catch (e) {
              console.warn('Could not load previous Steam data:', e.message);
            }
            
            try {
              if (fs.existsSync('./data/github-stats.json')) {
                previousGithubData = JSON.parse(fs.readFileSync('./data/github-stats.json', 'utf8'));
              }
            } catch (e) {
              console.warn('Could not load previous GitHub data:', e.message);
            }
            
            // --- STEAM ---
            const sKey = process.env.STEAM_API_KEY;
            const sId = process.env.STEAM_ID64 || '76561199034113344';
            if (sKey) {
              try {
                const r1 = await fetchWithRetry(`https://api.steampowered.com/ISteamUser/GetPlayerSummaries/v0002/?key=${sKey}&steamids=${sId}`);
                const j1 = await r1.json();
                
                if (!j1.response || !j1.response.players || j1.response.players.length === 0) {
                  throw new Error('Invalid Steam API response');
                }
                
                const r2 = await fetchWithRetry(`https://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key=${sKey}&steamid=${sId}&include_appinfo=0&include_played_free_games=1`);
                const j2 = await r2.json();
                const p = j1.response.players[0];
                
                const stats = {
                  steam: {
                    personastate: p.personastate || 0,
                    gameextrainfo: sanitizeString(p.gameextrainfo) || null,
                    avatar: sanitizeString(p.avatarmedium) || '',
                    timecreated: p.timecreated || 0,
                    lastlogoff: p.lastlogoff || 0,
                    game_count: j2.response?.game_count || 0,
                    total_playtime: Math.round((j2.response?.games?.reduce((a,b)=>a+(b.playtime_forever||0),0)||0)/60)
                  },
                  lastUpdate: new Date().toISOString()
                };
                fs.writeFileSync('./data/steam-status.json', JSON.stringify(stats, null, 2));
                console.log('Steam data updated successfully');
              } catch (e) {
                console.error('Steam error:', e.message);
                // Keep previous data if update fails
                if (previousSteamData.steam) {
                  previousSteamData.lastUpdate = new Date().toISOString();
                  previousSteamData.error = e.message;
                  fs.writeFileSync('./data/steam-status.json', JSON.stringify(previousSteamData, null, 2));
                  console.log('Using previous Steam data as fallback');
                }
              }
            }

            // --- GITHUB ---
            if (isGithubTime) {
              const gUser = 'Piotrunius';
              const gHeaders = process.env.GITHUB_TOKEN ? { 'Authorization': `token ${process.env.GITHUB_TOKEN}` } : {};
              try {
                const uR = await fetchWithRetry(`https://api.github.com/users/${gUser}`, { headers: gHeaders });
                const uJ = await uR.json();
                
                if (!uJ.login) {
                  throw new Error('Invalid GitHub user response');
                }
                
                const sR = await fetchWithRetry(`https://api.github.com/users/${gUser}/starred?per_page=100`, { 
                  headers: {...gHeaders, 'Accept': 'application/vnd.github.star+json'} 
                });
                const starred = await sR.json();
                
                const cR = await fetchWithRetry(`https://api.github.com/search/commits?q=author:${gUser}`, { 
                  headers: {...gHeaders, 'Accept': 'application/vnd.github.cloak-preview'} 
                });
                const cJ = await cR.json();
                
                const stats = {
                  summary: { 
                    projects: uJ.public_repos || 0, 
                    starredCount: Array.isArray(starred) ? starred.length : 0, 
                    commits: cJ.total_count || 0 
                  },
                  starred: Array.isArray(starred) ? starred.slice(0, 30).map(i => ({
                    name: sanitizeString(i.repo?.name || 'Unknown', 100),
                    owner: sanitizeString(i.repo?.owner?.login || 'Unknown', 50),
                    url: sanitizeString(i.repo?.html_url || '#', 200),
                    stars: i.repo?.stargazers_count || 0,
                    language: sanitizeString(i.repo?.language || 'Code', 30),
                    description: sanitizeString(i.repo?.description || 'No description.', 200),
                    starredAt: i.starred_at || new Date().toISOString()
                  })) : [],
                  recentCommits: [],
                  lastUpdate: new Date().toISOString()
                };
                
                // Fetch repositories with better error handling
                const reposR = await fetchWithRetry(`https://api.github.com/users/${gUser}/repos?per_page=100&sort=updated`, { headers: gHeaders });
                const repos = await reposR.json();
                
                if (!Array.isArray(repos)) {
                  throw new Error('Invalid repositories response');
                }
                
                // Parallel commit fetching with Promise.allSettled for better error handling
                const commitPromises = repos.slice(0, 15).map(async r => { // Reduced from 20 to 15 for efficiency
                  try {
                    const cr = await fetchWithRetry(
                      `https://api.github.com/repos/${r.owner.login}/${r.name}/commits?per_page=8&author=${gUser}`, 
                      { headers: gHeaders }
                    );
                    const cm = await cr.json();
                    if (Array.isArray(cm)) {
                      return cm.map(c => ({
                        message: sanitizeString(c.commit?.message?.split('\n')[0] || 'No message', 150),
                        repo: sanitizeString(r.name, 100),
                        author: sanitizeString(c.commit?.author?.name || 'Unknown', 50),
                        date: c.commit?.author?.date || new Date().toISOString(),
                        url: sanitizeString(c.html_url || '#', 200)
                      }));
                    }
                    return [];
                  } catch (e) {
                    console.log(`Skipping repo ${r.name}: ${e.message}`);
                    return [];
                  }
                });
                
                const allCommitsResults = await Promise.allSettled(commitPromises);
                const allCommits = allCommitsResults
                  .filter(r => r.status === 'fulfilled')
                  .flatMap(r => r.value);
                
                // Sort and deduplicate commits
                stats.recentCommits = allCommits
                  .sort((a, b) => new Date(b.date) - new Date(a.date))
                  .filter((commit, index, self) => 
                    index === self.findIndex(c => c.url === commit.url)
                  )
                  .slice(0, 40); // Reduced from 50 to 40 for smaller file size
                
                // Fetch security alerts (Dependabot, Code Scanning, Secret Scanning)
                const securityData = {
                  dependabot: { open: 0, closed: 0, alerts: [] },
                  codeScanning: { open: 0, closed: 0, alerts: [] },
                  secretScanning: { open: 0, closed: 0, alerts: [] },
                  totalOpen: 0,
                  lastChecked: new Date().toISOString()
                };
                
                // Fetch vulnerability alerts from all repos
                const securityPromises = repos.slice(0, 20).map(async r => {
                  const repoFullName = `${r.owner.login}/${r.name}`;
                  const results = { repo: r.name, dependabot: [], codeScanning: [], secretScanning: [] };
                  
                  try {
                    // Dependabot alerts
                    try {
                      const depR = await fetchWithRetry(
                        `https://api.github.com/repos/${repoFullName}/dependabot/alerts?state=open&per_page=10`,
                        { headers: gHeaders }
                      );
                      if (depR.ok) {
                        const depAlerts = await depR.json();
                        if (Array.isArray(depAlerts)) {
                          results.dependabot = depAlerts.map(a => ({
                            number: a.number,
                            state: a.state,
                            severity: sanitizeString(a.security_advisory?.severity || 'unknown', 20),
                            package: sanitizeString(a.dependency?.package?.name || 'unknown', 100),
                            summary: sanitizeString(a.security_advisory?.summary || 'No summary', 200),
                            url: sanitizeString(a.html_url || '#', 200),
                            created: a.created_at || new Date().toISOString()
                          }));
                        }
                      }
                    } catch (e) {
                      console.log(`Dependabot alerts not available for ${r.name}`);
                    }
                    
                    // Code scanning alerts
                    try {
                      const codeR = await fetchWithRetry(
                        `https://api.github.com/repos/${repoFullName}/code-scanning/alerts?state=open&per_page=10`,
                        { headers: gHeaders }
                      );
                      if (codeR.ok) {
                        const codeAlerts = await codeR.json();
                        if (Array.isArray(codeAlerts)) {
                          results.codeScanning = codeAlerts.map(a => ({
                            number: a.number,
                            state: a.state,
                            severity: sanitizeString(a.rule?.severity || 'unknown', 20),
                            rule: sanitizeString(a.rule?.description || 'Unknown rule', 200),
                            tool: sanitizeString(a.tool?.name || 'unknown', 50),
                            url: sanitizeString(a.html_url || '#', 200),
                            created: a.created_at || new Date().toISOString()
                          }));
                        }
                      }
                    } catch (e) {
                      console.log(`Code scanning alerts not available for ${r.name}`);
                    }
                    
                    // Secret scanning alerts
                    try {
                      const secretR = await fetchWithRetry(
                        `https://api.github.com/repos/${repoFullName}/secret-scanning/alerts?state=open&per_page=10`,
                        { headers: gHeaders }
                      );
                      if (secretR.ok) {
                        const secretAlerts = await secretR.json();
                        if (Array.isArray(secretAlerts)) {
                          results.secretScanning = secretAlerts.map(a => ({
                            number: a.number,
                            state: a.state,
                            secret_type: sanitizeString(a.secret_type || 'unknown', 100),
                            url: sanitizeString(a.html_url || '#', 200),
                            created: a.created_at || new Date().toISOString()
                          }));
                        }
                      }
                    } catch (e) {
                      console.log(`Secret scanning alerts not available for ${r.name}`);
                    }
                  } catch (e) {
                    console.log(`Security check failed for ${r.name}: ${e.message}`);
                  }
                  
                  return results;
                });
                
                const securityResults = await Promise.allSettled(securityPromises);
                
                // Aggregate security data
                securityResults.forEach(result => {
                  if (result.status === 'fulfilled' && result.value) {
                    const data = result.value;
                    
                    data.dependabot.forEach(alert => {
                      securityData.dependabot.open++;
                      securityData.dependabot.alerts.push({
                        ...alert,
                        repo: data.repo
                      });
                    });
                    
                    data.codeScanning.forEach(alert => {
                      securityData.codeScanning.open++;
                      securityData.codeScanning.alerts.push({
                        ...alert,
                        repo: data.repo
                      });
                    });
                    
                    data.secretScanning.forEach(alert => {
                      securityData.secretScanning.open++;
                      securityData.secretScanning.alerts.push({
                        ...alert,
                        repo: data.repo
                      });
                    });
                  }
                });
                
                // Sort alerts by severity and date
                const severityOrder = { critical: 0, high: 1, medium: 2, low: 3, unknown: 4 };
                securityData.dependabot.alerts.sort((a, b) => {
                  const severityDiff = (severityOrder[a.severity] || 4) - (severityOrder[b.severity] || 4);
                  if (severityDiff !== 0) return severityDiff;
                  return new Date(b.created) - new Date(a.created);
                });
                
                securityData.codeScanning.alerts.sort((a, b) => {
                  const severityDiff = (severityOrder[a.severity] || 4) - (severityOrder[b.severity] || 4);
                  if (severityDiff !== 0) return severityDiff;
                  return new Date(b.created) - new Date(a.created);
                });
                
                securityData.secretScanning.alerts.sort((a, b) => 
                  new Date(b.created) - new Date(a.created)
                );
                
                // Limit alerts to top 20 each
                securityData.dependabot.alerts = securityData.dependabot.alerts.slice(0, 20);
                securityData.codeScanning.alerts = securityData.codeScanning.alerts.slice(0, 20);
                securityData.secretScanning.alerts = securityData.secretScanning.alerts.slice(0, 20);
                
                securityData.totalOpen = securityData.dependabot.open + 
                                        securityData.codeScanning.open + 
                                        securityData.secretScanning.open;
                
                stats.security = securityData;
                
                // Fetch pull requests
                try {
                  const prR = await fetchWithRetry(
                    `https://api.github.com/search/issues?q=author:${gUser}+type:pr&sort=updated&per_page=10`,
                    { headers: gHeaders }
                  );
                  const prData = await prR.json();
                  
                  stats.pullRequests = {
                    total: prData.total_count || 0,
                    recent: Array.isArray(prData.items) ? prData.items.slice(0, 10).map(pr => ({
                      title: sanitizeString(pr.title || 'No title', 150),
                      repo: sanitizeString(pr.repository_url?.split('/').slice(-1)[0] || 'Unknown', 100),
                      state: pr.state || 'unknown',
                      url: sanitizeString(pr.html_url || '#', 200),
                      created: pr.created_at || new Date().toISOString(),
                      updated: pr.updated_at || new Date().toISOString()
                    })) : []
                  };
                } catch (e) {
                  console.log('PR fetch failed:', e.message);
                  stats.pullRequests = { total: 0, recent: [] };
                }
                
                // Fetch issues
                try {
                  const issueR = await fetchWithRetry(
                    `https://api.github.com/search/issues?q=author:${gUser}+type:issue&sort=updated&per_page=10`,
                    { headers: gHeaders }
                  );
                  const issueData = await issueR.json();
                  
                  stats.issues = {
                    total: issueData.total_count || 0,
                    recent: Array.isArray(issueData.items) ? issueData.items.slice(0, 10).map(issue => ({
                      title: sanitizeString(issue.title || 'No title', 150),
                      repo: sanitizeString(issue.repository_url?.split('/').slice(-1)[0] || 'Unknown', 100),
                      state: issue.state || 'unknown',
                      url: sanitizeString(issue.html_url || '#', 200),
                      created: issue.created_at || new Date().toISOString(),
                      updated: issue.updated_at || new Date().toISOString()
                    })) : []
                  };
                } catch (e) {
                  console.log('Issues fetch failed:', e.message);
                  stats.issues = { total: 0, recent: [] };
                }
                
                // Calculate language statistics
                const languageStats = {};
                repos.forEach(r => {
                  if (r.language) {
                    languageStats[r.language] = (languageStats[r.language] || 0) + 1;
                  }
                });
                
                stats.languages = Object.entries(languageStats)
                  .sort((a, b) => b[1] - a[1])
                  .slice(0, 10)
                  .map(([lang, count]) => ({ name: lang, repos: count }));
                
                fs.writeFileSync('./data/github-stats.json', JSON.stringify(stats, null, 2));
                console.log('GitHub data updated successfully');
              } catch (e) {
                console.error('GitHub error:', e.message);
                // Keep previous data if update fails
                if (previousGithubData.summary) {
                  previousGithubData.lastUpdate = new Date().toISOString();
                  previousGithubData.error = e.message;
                  fs.writeFileSync('./data/github-stats.json', JSON.stringify(previousGithubData, null, 2));
                  console.log('Using previous GitHub data as fallback');
                }
              }
            }
          }
          
          run().catch(error => {
            console.error('Fatal error:', error);
            process.exit(1);
          });
          EOF
          export IS_MANUAL="${{ github.event_name == 'workflow_dispatch' || github.event_name == 'push' }}"
          node update.js

      - name: Commit Changes
        id: commit
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add data/*.json
          if ! git diff --staged --quiet; then
            git commit -m "chore: automated stats update"
            git pull --rebase origin main
            git push origin main
            echo "changed=true" >> $GITHUB_OUTPUT
            echo "✅ Data updated successfully"
          else
            echo "changed=false" >> $GITHUB_OUTPUT
            echo "ℹ️  No changes detected"
          fi

      - name: Check for Errors
        if: failure()
        run: |
          echo "::warning::Workflow failed. Check the logs above for details."
          echo "Last successful run data will be used for the website."

      - name: Setup Pages
        if: steps.commit.outputs.changed == 'true' || github.event_name == 'workflow_dispatch' || github.event_name == 'push'
        uses: actions/configure-pages@v5
        
      - name: Upload artifact
        if: steps.commit.outputs.changed == 'true' || github.event_name == 'workflow_dispatch' || github.event_name == 'push'
        uses: actions/upload-pages-artifact@v3
        with:
          path: '.'
          
      - name: Deploy to GitHub Pages
        id: deployment
        if: steps.commit.outputs.changed == 'true' || github.event_name == 'workflow_dispatch' || github.event_name == 'push'
        uses: actions/deploy-pages@v4
